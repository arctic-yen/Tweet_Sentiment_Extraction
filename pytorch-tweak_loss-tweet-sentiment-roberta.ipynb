{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"pytorch-loss-tweet-sentiment-roberta.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"irnJyqdYNWRx","colab_type":"code","colab":{},"outputId":"97e2ed8a-e361-4651-f0bf-68f9c1c6134a"},"source":["import math\n","import glob\n","import sys\n","import gc\n","import os\n","import re\n","import random\n","from math import floor, ceil\n","\n","import pandas as pd\n","import numpy as np\n","from tqdm.autonotebook import tqdm\n","#TF&K\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import lr_scheduler\n","\n","from sklearn import metrics\n","from sklearn.model_selection import StratifiedKFold\n","\n","import transformers\n","from transformers import *\n","import tokenizers\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","import numpy as np\n","import pandas as pd\n","import os\n","import warnings\n","import random\n","import torch \n","from torch import nn"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:12: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  if sys.path[0] == '':\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"z9xNTT9SNWR3","colab_type":"code","colab":{}},"source":["def seed_everything(framework,SEED):\n","    random.seed(SEED)\n","    os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n","    np.random.seed(SEED)\n","    if framework == 'Pytorch':\n","        torch.manual_seed(SEED)\n","        if torch.cuda.is_available(): \n","            torch.cuda.manual_seed(SEED)\n","            torch.cuda.manual_seed_all(SEED)\n","            torch.backends.cudnn.deterministic = True\n","            torch.backends.cudnn.benchmark = True\n","    elif framework == 'Tensorflow':\n","        tf.random.set_seed(SEED)\n","        \n","framework = 'Pytorch'\n","SEED = 88888\n","seed_everything(framework, SEED)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KSc59IE2NWR6","colab_type":"code","colab":{}},"source":["MAX_LEN = 96\n","BATCH_SIZE = 32\n","EPOCHS = 3\n","ROBERTA_PATH = \"../input/roberta-base/\"\n","TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n","    vocab_file=f\"{ROBERTA_PATH}/vocab.json\", \n","    merges_file=f\"{ROBERTA_PATH}/merges.txt\", \n","    lowercase=True,\n","    add_prefix_space=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C9qtKnJDNWR9","colab_type":"code","colab":{}},"source":["class TweetDataset(torch.utils.data.Dataset):\n","    def __init__(self, df):\n","        self.df = df\n","        self.max_len = MAX_LEN\n","        self.labeled = 'selected_text' in df\n","        self.tokenizer = TOKENIZER\n","\n","    def __getitem__(self, index):\n","        data = {}\n","        row = self.df.iloc[index]\n","        \n","        ids, masks, tweet, offsets = self.get_input_data(row)\n","        data['ids'] = ids\n","        data['masks'] = masks\n","        data['tweet'] = tweet\n","        data['offsets'] = offsets\n","        \n","        if self.labeled:\n","            start_idx, end_idx = self.get_target_idx(row, tweet, offsets)\n","            data['start_idx'] = start_idx\n","            data['end_idx'] = end_idx\n","        \n","        return data\n","\n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def get_input_data(self, row):\n","        tweet = \" \" + \" \".join(row.text.lower().split())\n","        encoding = self.tokenizer.encode(tweet)\n","        sentiment_id = self.tokenizer.encode(row.sentiment).ids\n","        ids = [0] + sentiment_id + [2, 2] + encoding.ids + [2]\n","        #ids = [0] + encoding.ids + [2, 2] + sentiment_id + [2]\n","        offsets = [(0, 0)] * 4 + encoding.offsets + [(0, 0)]\n","                \n","        pad_len = self.max_len - len(ids)\n","        if pad_len > 0:\n","            ids += [1] * pad_len\n","            offsets += [(0, 0)] * pad_len\n","        \n","        ids = torch.tensor(ids)\n","        masks = torch.where(ids != 1, torch.tensor(1), torch.tensor(0))\n","        offsets = torch.tensor(offsets)\n","        \n","        return ids, masks, tweet, offsets\n","        \n","    def get_target_idx(self, row, tweet, offsets):\n","        selected_text = \" \" +  \" \".join(row.selected_text.lower().split())\n","\n","        len_st = len(selected_text) - 1\n","        idx0 = None\n","        idx1 = None\n","\n","        for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n","            if \" \" + tweet[ind: ind+len_st] == selected_text:\n","                idx0 = ind\n","                idx1 = ind + len_st - 1\n","                break\n","\n","        char_targets = [0] * len(tweet)\n","        if idx0 != None and idx1 != None:\n","            for ct in range(idx0, idx1 + 1):\n","                char_targets[ct] = 1\n","\n","        target_idx = []\n","        for j, (offset1, offset2) in enumerate(offsets):\n","            if sum(char_targets[offset1: offset2]) > 0:\n","                target_idx.append(j)\n","\n","        start_idx = target_idx[0]\n","        end_idx = target_idx[-1]\n","        \n","        return start_idx, end_idx\n","        \n","def get_train_val_loaders(df, train_idx, val_idx, batch_size=8):\n","    train_df = df.iloc[train_idx]\n","    val_df = df.iloc[val_idx]\n","\n","    train_loader = torch.utils.data.DataLoader(\n","        TweetDataset(train_df), \n","        batch_size=batch_size, \n","        shuffle=True, \n","        num_workers=2,\n","        drop_last=True)\n","\n","    val_loader = torch.utils.data.DataLoader(\n","        TweetDataset(val_df), \n","        batch_size=batch_size, \n","        shuffle=False, \n","        num_workers=2)\n","\n","    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n","\n","    return dataloaders_dict\n","\n","def get_test_loader(df, batch_size=32):\n","    loader = torch.utils.data.DataLoader(\n","        TweetDataset(df), \n","        batch_size=batch_size, \n","        shuffle=False, \n","        num_workers=2)    \n","    return loader"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YtgRoaX2NWSA","colab_type":"code","colab":{}},"source":["class TweetModel(nn.Module):\n","    def __init__(self):\n","        super(TweetModel, self).__init__()\n","        #config = RobertaConfig.from_pretrained(ROBERTA_PATH+'config.json', output_hidden_states=True)    \n","        #self.roberta = RobertaModel.from_pretrained(ROBERTA_PATH+'pytorch_model.bin', config=config)\n","        config = RobertaConfig.from_pretrained('../input/robertabasepretraining/cp15000-config.json', output_hidden_states=True)\n","        self.roberta = RobertaModel.from_pretrained('../input/robertabasepretraining/cp15000-pytorch_model.bin', config=config)\n","        \n","        self.dropout = nn.Dropout(0.2)\n","        self.fc = nn.Linear(config.hidden_size, 2)\n","        nn.init.normal_(self.fc.weight, std=0.02)\n","        nn.init.normal_(self.fc.bias, 0)\n","\n","    def forward(self, input_ids, attention_mask):\n","        _, _, hs = self.roberta(input_ids, attention_mask)\n","         \n","        x = torch.stack([hs[-1], hs[-2], hs[-3], hs[-4]])\n","        x = torch.mean(x, 0)\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","        start_logits, end_logits = x.split(1, dim=-1)\n","        start_logits = start_logits.squeeze(-1)\n","        end_logits = end_logits.squeeze(-1)\n","                \n","        return start_logits, end_logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"01E3HO0vNWSM","colab_type":"code","colab":{}},"source":["# Normal loss function\n","\"\"\"\n","def loss_fn(start_logits, end_logits, start_positions, end_positions):\n","    ce_loss = nn.CrossEntropyLoss()\n","    start_loss = ce_loss(start_logits, start_positions)\n","    end_loss = ce_loss(end_logits, end_positions)    \n","    total_loss = start_loss + end_loss\n","    return total_loss\n","\"\"\"\n","\n","# position weight loss function\n","\"\"\"\n","def pos_weight(pred_tensor, pos_tensor, neg_weight=1, pos_weight=1):\n","    # neg_weight for when pred position < target position\n","    # pos_weight for when pred position > target position\n","    gap = torch.argmax(pred_tensor, dim=1) - pos_tensor\n","    gap = gap.type(torch.float32)\n","    return torch.where(gap < 0, -neg_weight * gap, pos_weight * gap)\n","\n","def loss_fn(start_logits, end_logits, start_positions, end_positions):\n","    loss_fct = nn.CrossEntropyLoss(reduce='none') # do reduction later\n","    \n","    start_loss = loss_fct(start_logits, start_positions) * pos_weight(start_logits, start_positions, 1, 1)\n","    end_loss = loss_fct(end_logits, end_positions) * pos_weight(end_logits, end_positions, 1, 1)\n","    \n","    start_loss = torch.mean(start_loss)\n","    end_loss = torch.mean(end_loss)\n","    \n","    total_loss = (start_loss + end_loss)\n","    return total_loss\n","\"\"\"\n","\n","# distance loss function\n","def dist_between(start_logits, end_logits, device='cpu', max_seq_len=128):\n","    \"\"\"get dist btw. pred & ground_truth\"\"\"\n","\n","    linear_func = torch.tensor(np.linspace(0, 1, max_seq_len, endpoint=False), requires_grad=False)\n","    linear_func = linear_func.to(device)\n","\n","    start_pos = (start_logits*linear_func).sum(axis=1)\n","    end_pos = (end_logits*linear_func).sum(axis=1)\n","\n","    diff = end_pos-start_pos\n","\n","    return diff.sum(axis=0)/diff.size(0)\n","\n","\n","def dist_loss_fn(start_logits, end_logits, start_positions, end_positions, device='cpu', max_seq_len=128, scale=1):\n","    \"\"\"calculate distance loss between prediction's length & GT's length\n","    \n","    Input\n","    - start_logits ; shape (batch, max_seq_len{128})\n","        - logits for start index\n","    - end_logits\n","        - logits for end index\n","    - start_positions ; shape (batch, 1)\n","        - start index for GT\n","    - end_positions\n","        - end index for GT\n","    \"\"\"\n","    start_logits = torch.nn.Softmax(1)(start_logits) # shape ; (batch, max_seq_len)\n","    end_logits = torch.nn.Softmax(1)(end_logits)\n","    \n","    start_one_hot = torch.nn.functional.one_hot(start_positions, num_classes=max_seq_len).to(device)\n","    end_one_hot = torch.nn.functional.one_hot(end_positions, num_classes=max_seq_len).to(device)\n","    \n","    pred_dist = dist_between(start_logits, end_logits, device, max_seq_len)\n","    gt_dist = dist_between(start_one_hot, end_one_hot, device, max_seq_len) # always positive\n","    diff = (gt_dist-pred_dist)\n","\n","    rev_diff_squared = 1-torch.sqrt(diff*diff) # as diff is smaller, make it get closer to the one\n","    loss = -torch.log(rev_diff_squared) # by using negative log function, if argument is near zero -> inifinite, near one -> zero\n","\n","    return loss*scale\n","\n","\n","def loss_fn(start_logits, end_logits, start_positions, end_positions):\n","    ce_loss = nn.CrossEntropyLoss()\n","    start_loss = ce_loss(start_logits, start_positions)\n","    end_loss = ce_loss(end_logits, end_positions)    \n","    idx_loss = (start_loss+end_loss)\n","    \n","    dist_loss = dist_loss_fn(start_logits, end_logits,\n","                             start_positions, end_positions,\n","                             device, MAX_LEN)\n","    total_loss = idx_loss + dist_loss\n","    \n","    return total_loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"igLzpNAxNWSQ","colab_type":"code","colab":{}},"source":["def get_selected_text(text, start_idx, end_idx, offsets):\n","    selected_text = \"\"\n","    for ix in range(start_idx, end_idx + 1):\n","        selected_text += text[offsets[ix][0]: offsets[ix][1]]\n","        if (ix + 1) < len(offsets) and offsets[ix][1] < offsets[ix + 1][0]:\n","            selected_text += \" \"\n","    return selected_text\n","\n","def jaccard(str1, str2): \n","    a = set(str1.lower().split()) \n","    b = set(str2.lower().split())\n","    c = a.intersection(b)\n","    return float(len(c)) / (len(a) + len(b) - len(c))\n","\n","def get_best_start_end_idxs(_start_logits, _end_logits):\n","    best_logit = -1000\n","    best_idxs = None\n","    for start_idx, start_logit in enumerate(_start_logits):\n","        for end_idx, end_logit in enumerate(_end_logits[start_idx:]):\n","            logit_sum = (start_logit + end_logit).item()\n","            if logit_sum > best_logit:\n","                best_logit = logit_sum\n","                best_idxs = (start_idx, start_idx+end_idx)\n","    return best_idxs\n","\n","def compute_jaccard_score(text, start_idx, end_idx, start_logits, end_logits, offsets):\n","    start_pred = np.argmax(start_logits)\n","    end_pred = np.argmax(end_logits)\n","\n","    if start_pred > end_pred:\n","        #pred = text\n","        pred = get_selected_text(text, end_pred, start_pred, offsets)\n","    else:\n","        pred = get_selected_text(text, start_pred, end_pred, offsets)\n","        \n","    true = get_selected_text(text, start_idx, end_idx, offsets)\n","    \n","    return jaccard(true, pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ykv5ItUcNWSV","colab_type":"code","colab":{}},"source":["def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs, filename):\n","    model.cuda()\n","    epoch_jaccard_best = 0.0\n","    epoch_loss_best = 999999.0\n","    for epoch in range(num_epochs):\n","        for phase in ['train', 'val']:\n","            if phase == 'train':\n","                model.train()\n","            else:\n","                model.eval()\n","\n","            epoch_loss = 0.0\n","            epoch_jaccard = 0.0\n","            \n","            \n","            for data in (dataloaders_dict[phase]):\n","                ids = data['ids'].cuda()\n","                masks = data['masks'].cuda()\n","                tweet = data['tweet']\n","                offsets = data['offsets'].numpy()\n","                start_idx = data['start_idx'].cuda()\n","                end_idx = data['end_idx'].cuda()\n","\n","                optimizer.zero_grad()\n","\n","                with torch.set_grad_enabled(phase == 'train'):\n","\n","                    start_logits, end_logits = model(ids, masks)\n","\n","                    loss = criterion(start_logits, end_logits, start_idx, end_idx)\n","\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                    epoch_loss += loss.item() * len(ids)\n","                    \n","                    start_idx = start_idx.cpu().detach().numpy()\n","                    end_idx = end_idx.cpu().detach().numpy()\n","                    start_logits = torch.softmax(start_logits, dim=1).cpu().detach().numpy()\n","                    end_logits = torch.softmax(end_logits, dim=1).cpu().detach().numpy()\n","                    \n","                    for i in range(len(ids)):                        \n","                        jaccard_score = compute_jaccard_score(\n","                            tweet[i],\n","                            start_idx[i],\n","                            end_idx[i],\n","                            start_logits[i], \n","                            end_logits[i], \n","                            offsets[i])\n","                        epoch_jaccard += jaccard_score\n","                    \n","            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n","            epoch_jaccard = epoch_jaccard / len(dataloaders_dict[phase].dataset)\n","            \n","            print('Epoch {}/{} | {:^5} | Loss: {:.4f} | Jaccard: {:.4f}'.format(\n","                epoch + 1, num_epochs, phase, epoch_loss, epoch_jaccard))\n","            if phase == 'val':\n","                if epoch_loss <= epoch_loss_best:\n","                    if epoch_loss == epoch_loss_best:\n","                        if epoch_jaccard > epoch_jaccard_best:\n","                            epoch_jaccard_best = epoch_jaccard\n","                            torch.save(model.state_dict(), filename)\n","                            print('Save model by Jaccard')\n","                    else:\n","                        epoch_loss_best = epoch_loss\n","                        torch.save(model.state_dict(), filename)\n","                        print('Save model by Loss')\n","                \n","    \n","    #torch.save(model.state_dict(), filename)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5xvZhfAONWSb","colab_type":"code","colab":{},"outputId":"ef321ed5-2f7c-4dd6-d7e6-dc44419173e8"},"source":["%%time\n","\n","train_df = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\n","train_df['text'] = train_df['text'].astype(str)\n","train_df['selected_text'] = train_df['selected_text'].astype(str)\n","\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n","\n","for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df.sentiment), start=1): \n","    print(f'Fold: {fold}')\n","\n","    model = TweetModel()\n","    optimizer = optim.AdamW(model.parameters(), lr=3e-5, betas=(0.9, 0.999))\n","    criterion = loss_fn    \n","    dataloaders_dict = get_train_val_loaders(train_df, train_idx, val_idx, BATCH_SIZE)\n","\n","    train_model(\n","        model, \n","        dataloaders_dict,\n","        criterion, \n","        optimizer, \n","        EPOCHS,\n","        f'roberta_fold{fold}.pth')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fold: 1\n","Epoch 1/3 | train | Loss: 2.1030 | Jaccard: 0.6643\n","Epoch 1/3 |  val  | Loss: 1.6976 | Jaccard: 0.6993\n","Save model by Loss\n","Epoch 2/3 | train | Loss: 1.6013 | Jaccard: 0.7209\n","Epoch 2/3 |  val  | Loss: 1.6354 | Jaccard: 0.7230\n","Save model by Loss\n","Epoch 3/3 | train | Loss: 1.4302 | Jaccard: 0.7425\n","Epoch 3/3 |  val  | Loss: 1.7054 | Jaccard: 0.7141\n","Fold: 2\n","Epoch 1/3 | train | Loss: 2.0238 | Jaccard: 0.6781\n","Epoch 1/3 |  val  | Loss: 1.6363 | Jaccard: 0.7141\n","Save model by Loss\n","Epoch 2/3 | train | Loss: 1.5590 | Jaccard: 0.7225\n","Epoch 2/3 |  val  | Loss: 1.6070 | Jaccard: 0.7256\n","Save model by Loss\n","Epoch 3/3 | train | Loss: 1.3927 | Jaccard: 0.7457\n","Epoch 3/3 |  val  | Loss: 1.6646 | Jaccard: 0.7244\n","Fold: 3\n","Epoch 1/3 | train | Loss: 2.0762 | Jaccard: 0.6682\n","Epoch 1/3 |  val  | Loss: 1.6531 | Jaccard: 0.7183\n","Save model by Loss\n","Epoch 2/3 | train | Loss: 1.5706 | Jaccard: 0.7236\n","Epoch 2/3 |  val  | Loss: 1.6071 | Jaccard: 0.7236\n","Save model by Loss\n","Epoch 3/3 | train | Loss: 1.4148 | Jaccard: 0.7440\n","Epoch 3/3 |  val  | Loss: 1.6715 | Jaccard: 0.7177\n","Fold: 4\n","Epoch 1/3 | train | Loss: 2.0408 | Jaccard: 0.6748\n","Epoch 1/3 |  val  | Loss: 1.6519 | Jaccard: 0.7121\n","Save model by Loss\n","Epoch 2/3 | train | Loss: 1.5518 | Jaccard: 0.7263\n","Epoch 2/3 |  val  | Loss: 1.6725 | Jaccard: 0.7072\n","Epoch 3/3 | train | Loss: 1.3802 | Jaccard: 0.7499\n","Epoch 3/3 |  val  | Loss: 1.7300 | Jaccard: 0.7092\n","Fold: 5\n","Epoch 1/3 | train | Loss: 2.0959 | Jaccard: 0.6700\n","Epoch 1/3 |  val  | Loss: 1.6666 | Jaccard: 0.7136\n","Save model by Loss\n","Epoch 2/3 | train | Loss: 1.5864 | Jaccard: 0.7240\n","Epoch 2/3 |  val  | Loss: 1.6084 | Jaccard: 0.7167\n","Save model by Loss\n","Epoch 3/3 | train | Loss: 1.4295 | Jaccard: 0.7416\n","Epoch 3/3 |  val  | Loss: 1.6685 | Jaccard: 0.7188\n","CPU times: user 40min 1s, sys: 17min 17s, total: 57min 19s\n","Wall time: 59min 28s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wU_SDRwjNWSf","colab_type":"code","colab":{},"outputId":"16d1c470-cedf-401e-ff25-b2e5bbcf5cfb"},"source":["%%time\n","\n","test_df = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\n","test_df['text'] = test_df['text'].astype(str)\n","test_loader = get_test_loader(test_df)\n","predictions = []\n","models = []\n","for fold in range(skf.n_splits):\n","    model = TweetModel()\n","    model.cuda()\n","    model.load_state_dict(torch.load(f'roberta_fold{fold+1}.pth'))\n","    model.eval()\n","    models.append(model)\n","\n","for data in test_loader:\n","    ids = data['ids'].cuda()\n","    masks = data['masks'].cuda()\n","    tweet = data['tweet']\n","    offsets = data['offsets'].numpy()\n","\n","    start_logits = []\n","    end_logits = []\n","    for model in models:\n","        with torch.no_grad():\n","            output = model(ids, masks)\n","            start_logits.append(torch.softmax(output[0], dim=1).cpu().detach().numpy())\n","            end_logits.append(torch.softmax(output[1], dim=1).cpu().detach().numpy())\n","\n","    start_logits = np.mean(start_logits, axis=0)\n","    end_logits = np.mean(end_logits, axis=0)\n","    for i in range(len(ids)):    \n","        #start_pred = np.argmax(start_logits[i])\n","        #end_pred = np.argmax(end_logits[i])\n","        best = get_best_start_end_idxs(start_logits[i],end_logits[i])\n","        start_pred, end_pred = best[0], best[1]\n","        if start_pred > end_pred:\n","            pred = tweet[i]\n","        else:\n","            pred = get_selected_text(tweet[i], start_pred, end_pred, offsets[i])\n","        predictions.append(pred)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CPU times: user 1min 13s, sys: 20.7 s, total: 1min 34s\n","Wall time: 1min 35s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mNijqgGcNWSi","colab_type":"code","colab":{}},"source":["def post_process(selected):\n","    return \" \".join(set(selected.lower().split()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nUta0lfaNWSn","colab_type":"code","colab":{},"outputId":"2c8850c6-4766-41d3-8155-4eed9f4937f8"},"source":["sub_df = pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')\n","sub_df['selected_text'] = predictions\n","sub_df.selected_text = sub_df.selected_text.map(post_process)\n","sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('!!!!', '!') if len(x.split())==1 else x)\n","sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('..', '.') if len(x.split())==1 else x)\n","sub_df['selected_text'] = sub_df['selected_text'].apply(lambda x: x.replace('...', '.') if len(x.split())==1 else x)\n","sub_df.to_csv('submission.csv', index=False)\n","sub_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>textID</th>\n","      <th>selected_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>f87dea47db</td>\n","      <td>day of last the session</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>96d74cb729</td>\n","      <td>exciting</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>eee518ae67</td>\n","      <td>a such shame!</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>01082688c6</td>\n","      <td>happy bday!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>33987a8ee5</td>\n","      <td>i it!! like</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       textID            selected_text\n","0  f87dea47db  day of last the session\n","1  96d74cb729                 exciting\n","2  eee518ae67            a such shame!\n","3  01082688c6              happy bday!\n","4  33987a8ee5              i it!! like"]},"metadata":{"tags":[]},"execution_count":14}]}]}